---
layout: post
title: Module 6 â€“ Week 3
date: 17-11-2025
categories: [AIO2025, Module6, Deep Learning]
use_math: true
image: /assets/module6-week3/mlp.png
---

{% include mathjax.html %}

# **Multi-layer Perceptron**

If Deep Learning were a "big family" of models, the **Multi-layer Perceptron (MLP)** would be the first-born child â€” simple, intuitive, and yet responsible for laying the foundation for nearly every advanced architecture that followed, including CNNs, RNNs, Transformers, and modern diffusion models.

<p align="left">
  <img src="{{ '/assets/module6-week3/intro.jpg' | relative_url }}" alt="Pipeline Diagram" width="700">
</p> 

Before MLPs became widely adopted, many tasks relied on linear models such as **Linear Regression**, **Logistic Regression**, or **Softmax Regression**. While effective in basic scenarios, these models share a fundamental limitation: **they can only learn linear relationships between inputs and outputs**.

As a result, they fail when the data contains nonlinear structures, for example:

- when the decision boundary is curved or highly complex,
- when features interact in nonlinear ways,
- or when the data forms shapes that cannot be separated by a straight line, such as concentric circles.

In these cases, linear models are inherently limited because **they can only produce straight, flat decision boundaries**.

The need to capture nonlinear patterns naturally led to the introduction of the MLP. By stacking **multiple linear layers** and applying **nonlinear activation functions**, an MLP can "bend" the input space, allowing the model to learn complex mappings that traditional linear models cannot represent.

## **Part 1 â€“ Review of Softmax Regression**

Softmax Regression is an extension of logistic regression designed for **multi-class classification**. Instead of producing a single probability for the positive class, it outputs a **probability distribution** across all possible classes.

### **1. Model Formulation**

For an input vector $x$, each class $k$ is assigned a score:

$$
z_k = w_k^T x + b_k
$$

These scores are then converted into normalized probabilities using the softmax function:

$$
\text{softmax}(z_k) = \frac{\exp(z_k)}{\sum_{j=1}^{K} \exp(z_j)}
$$

This ensures two properties essential for multi-class prediction:

- each predicted value is non-negative,
- and the entire set of outputs sums to 1.

**Cross-Entropy Loss**

Softmax Regression is typically trained using the **Cross-Entropy Loss**, which compares the model's predicted distribution with the true class distribution (commonly represented as a one-hot vector).

For the correct class $y$:

$$
L = - \log(p_y)
$$

This loss penalizes the model proportionally to how much probability it assigns to the true class.

General procedure of **Softmax Regression** using **Gradient Descent**:

<p align="center">
  <img src="{{ '/assets/module6-week3/softmaxregression.png' | relative_url }}" alt="Pipeline Diagram" width="600">
</p> 

### **2. Relation to MLP Output Layers**

The combination of **Softmax** and **Cross-Entropy** is widely regarded as the standard choice for the output layer in classification models. Softmax converts the raw logits into a meaningful probability distribution over the classes, allowing the network to express how confident it is in each prediction.

At the same time, the Cross-Entropy loss measures how far the predicted probability distribution is from the true label distribution. This loss provides a clear learning signal that guides the model during training, helping it adjust its weights in the right direction.

When used as the final stage of an MLP, the Softmax and Cross-Entropy pair forms an effective prediction mechanism. The hidden layers focus on extracting and representing relevant features, while the output layer interprets these representations by producing probabilities and evaluating how accurate they are. This combination has become a widely adopted choice in modern neural network architectures because of its stability, efficiency, and strong performance in classification tasks.

## **Part 2 â€“ Multi-layer Perceptron**

### **1. Single-layer Perceptron**

A single-layer perceptron is the simplest form of an artificial neural network. It consists of a single computational unit that receives several input features, combines them through a weighted linear function, and produces an output through an activation function. Despite its simplicity, it is an important conceptual foundation for understanding how more complex neural networks operate.

### How it works

<p align="center">
  <img src="{{ '/assets/module6-week3/single-perceptron.png' | relative_url }}" alt="Pipeline Diagram" width="600">
</p> 

The perceptron takes an input vector $x = (x_1, x_2, ..., x_m)$. Each input is multiplied by a corresponding weight $w_i$, and together with a bias term $b$, they form a linear combination:

$$
z = \sum_{i=1}^{m} w_i x_i + b
$$

The resulting value is then passed through an activation function $\phi(z)$, typically a threshold-based function for binary decisions:

$$
\hat{y} = \phi(z)
$$

This computation enables the perceptron to determine how strongly each input feature contributes to the final decision.

### Interpretation

A single-layer perceptron acts as a linear classifier. It divides the input space using a hyperplane: points on one side of the hyperplane are assigned to one class, while points on the other side are assigned to another. This makes the perceptron suitable for problems where the classes are linearly separable â€” that is, when a straight boundary is sufficient to distinguish between them.

### Limitations

Because all computations in the perceptron are linear, it cannot capture nonlinear patterns in data. Tasks where decision boundaries are curved or where class structures are intertwined cannot be learned by this model. As a result, the single-layer perceptron is inadequate for many practical problems where feature interactions are complex and inherently nonlinear.

### Direction of development

To overcome these limitations, multiple perceptrons can be stacked into successive layers. By introducing intermediate hidden layers along with nonlinear activation functions, the model gains the ability to represent complex, nonlinear mappings. This layered extension leads to the architecture known as the **Multi-layer Perceptron (MLP)**, which forms the basis for more advanced deep learning models.

### **2. Multi-layer Perceptron**

A Multi-layer Perceptron (MLP) is a neural network architecture composed of multiple layers of transformations applied sequentially. At each layer, the network performs a linear combination of the incoming signals, followed by a nonlinear activation function. Through this layered composition, an MLP can model complex relationships between the input and the output, far beyond the capability of a single-layer perceptron.

### General Structure

An MLP consists of three main parts: the input layer, the hidden layers, and the output layer.

At layer $\ell$, each neuron receives all activations from the previous layer, combines them using weights and a bias term, and produces a pre-activation value:

$$
z_j^{(\ell)} = \sum_i w_{ij}^{(\ell)} a_i^{(\ell-1)} + b_j^{(\ell)}
$$

Where:

- $a_i^{(\ell-1)}$: activation of neuron $i$ in the previous layer
- $w_{ij}^{(\ell)}$: weight connecting neuron $i$ (layer $\ell - 1$) to neuron $j$ (layer $\ell$)
- $b_j^{(\ell)}$: bias of neuron $j$ in layer $\ell$
- $z_j^{(\ell)}$: pre-activation value at layer $\ell$

The pre-activation is then passed through a nonlinear activation function to produce the neuron's output:

$$
a_j^{(\ell)} = \phi\left(z_j^{(\ell)}\right)
$$

Where:

- $\phi(\cdot)$: nonlinear activation function (sigmoid, tanh, ReLU, etc.)
- $a_j^{(\ell)}$: activation of neuron $j$ in layer $\ell$

These transformations repeat across all layers, similar to letting data pass through a series of "filters," with each layer reshaping the representation in its own way.

### Role of Each Layer

<p align="center">
  <img src="{{ '/assets/module6-week3/mlp.png' | relative_url }}" alt="Pipeline Diagram" width="600">
</p> 

The **input layer** passes the raw data into the network as a feature vector.

The **hidden layers** perform the essential work of representation learning: they mix the features through linear transformations and then apply nonlinear activations, allowing the model to gradually uncover richer and more abstract patterns. Across layers, the data becomes increasingly structured toward the final task.

The **output layer** takes the final transformed representation and produces a predictionâ€”either a numeric value for regression or a probability distribution for classification.

### Mathematical Representation

From a mathematical perspective, an MLP is a composition of functions.

For layer $\ell$, the parameters consist of a weight matrix and bias vector:

$$
W^{(\ell)} \in \mathbb{R}^{d^{(\ell)} \times d^{(\ell-1)}}, \quad b^{(\ell)} \in \mathbb{R}^{d^{(\ell)}}
$$

The output layer is defined using:

$$
W^{(L+1)} \in \mathbb{R}^{d^{(L+1)} \times d^{(L)}}, \quad b^{(L+1)} \in \mathbb{R}^{d^{(L+1)}}
$$

The alternating sequence of linear and nonlinear operations allows the model to express highly flexible functions.

### Function and Interpretation of Layer Transformations

Each layer in the MLP can be seen as a mapping from one representation space to another.

If only linear mappings were used, the entire network would collapse into a single linear function. However, the inclusion of nonlinear activations after each layer gives the network the ability to bend, reshape, and reorganize the data distribution. This allows the MLP to separate patterns that are not linearly separable in the original input space.

### Representation Capability of MLP

With a sufficient number of neurons and layers, an MLP can approximate a wide variety of continuous functions. This makes it a powerful model for vector-based data and an essential foundation for many modern deep learning architectures.

### Activation Functions

Activation functions play a central role in Multi-layer Perceptrons. At each neuron, they transform the linear combination of inputs into a nonlinear output. Without activation functions, an MLP would collapse into a single linear transformation, regardless of how many layers it contains. The activation function is therefore what enables the network to model complex, nonlinear patterns in data.

#### Nonlinear transformation

After computing the pre-activation value

$$
z_j^{(\ell)} = \sum_i w_{ij}^{(\ell)} a_i^{(\ell-1)} + b_j^{(\ell)},
$$

the neuron applies an activation function $\phi(\cdot)$ to obtain the final output:

$$
a_j^{(\ell)} = \phi\left(z_j^{(\ell)}\right).
$$

Where:

- $\phi(\cdot)$: a nonlinear activation function
- $a_j^{(\ell)}$: activation (output) of neuron $j$
- $z_j^{(\ell)}$: pre-activation value at layer $\ell$

This small nonlinear transformation dramatically expands the expressive capacity of the entire network.

#### Why activation functions matter

Activation functions determine how information flows through the network.

They control:

- **nonlinearity**, enabling the model to fit complex patterns
- **gradient behavior**, affecting how easily the model learns
- **range and scale**, influencing the stability of forward and backward propagation
- **representational power**, affecting the kinds of functions the network can approximate

Choosing an appropriate activation function is therefore crucial for effective training. In modern practice, ReLU and its variants are dominant in hidden layers, while sigmoid and softmax are mainly used for output layers depending on the task.

<p align="center">
  <img src="{{ '/assets/module6-week3/activation_functions.png' | relative_url }}" alt="Pipeline Diagram" width="600">
</p> 

### **3. Forward Propagation**

Forward propagation is the process of passing data from the input layer â†’ hidden layers â†’ output layer to produce the final prediction. At each layer, the network performs two steps:

(1) linear combination using weights and bias,

(2) passing the result through a nonlinear activation function.

### Propagation through a single layer

At layer $\ell$, neuron $j$ computes the pre-activation value:

$$
z_j^{(\ell)} = \sum_i w_{ij}^{(\ell)} a_i^{(\ell-1)} + b_j^{(\ell)}.
$$

Where:

- $a_i^{(\ell-1)}$: output of neuron $i$ in the previous layer
- $w_{ij}^{(\ell)}$: connection weight
- $b_j^{(\ell)}$: bias
- $z_j^{(\ell)}$: pre-activation value

Then the neuron produces its output:

$$
a_j^{(\ell)} = \phi\left(z_j^{(\ell)}\right).
$$

Where:

- $\phi(\cdot)$: activation function (sigmoid, tanh, ReLU...)
- $a_j^{(\ell)}$: neuron output

### Propagation through the entire network

This process repeats across all layers:

$$
a^{(0)} = x, \qquad a^{(\ell)} = \phi\left(W^{(\ell)} a^{(\ell-1)} + b^{(\ell)}\right), \qquad \ell = 1, \ldots, L + 1.
$$

The final output $a^{(L+1)}$ is the model's prediction.

### Interpretation

Forward propagation serves three roles:

- **Data transformation**: each layer creates a new representation more useful than the previous layer.

- **Generating predictions**: the final value reflects the output the model believes to be correct.

- **Preparation for backpropagation**: all values $z^{(\ell)}$ and $a^{(\ell)}$ are stored for gradient computation.

### **4. Backpropagation**

After performing forward propagation and obtaining the predicted value $\hat{y}_i$, the next step is to measure the error between the prediction and the true value $y_i$. Backpropagation is used to propagate this error from the output layer back to the previous layers, thereby computing the gradient for each parameter. The entire process is based on the chain rule of derivatives, allowing us to quantify the influence of each weight on the output in the network.

---

### Gradient at the output layer

Suppose the loss function used here is **Mean Squared Error (MSE)**:

$$
L_i(\hat{y}_i, y_i) = (\hat{y}_i - y_i)^2, \qquad \frac{\partial L_i}{\partial \hat{y}_i} = 2(\hat{y}_i - y_i).
$$

The network output is computed as:

$$
\hat{y}_i = W^{(L+1)} a_i^{(L)} + b^{(L+1)}.
$$

Taking the derivative of $\hat{y}_i$ with respect to the parameters:

$$
\frac{\partial \hat{y}_i}{\partial W^{(L+1)}} = a_i^{(L)}, \qquad \frac{\partial \hat{y}_i}{\partial b^{(L+1)}} = 1.
$$

By the chain rule, we have:

$$
\frac{\partial L_i}{\partial W^{(L+1)}} = \frac{\partial L_i}{\partial \hat{y}_i} \frac{\partial \hat{y}_i}{\partial W^{(L+1)}} = 2(\hat{y}_i - y_i) \left(a_i^{(L)}\right)^\top,
$$

$$
\frac{\partial L_i}{\partial b^{(L+1)}} = \frac{\partial L_i}{\partial \hat{y}_i} = 2(\hat{y}_i - y_i).
$$

These derivatives represent the influence of the output weights and output bias on the overall error.

---

### Gradient at hidden layers

At hidden layer $\ell$, the output is defined by:

$$
a_i^{(\ell)} = \phi\left(z_i^{(\ell)}\right), \qquad z_i^{(\ell)} = W^{(\ell)} a_i^{(\ell-1)} + b^{(\ell)}.
$$

We need to propagate the error from layer $\ell + 1$ back to layer $\ell$. By the chain rule:

$$
\delta_i^{(\ell)} = \frac{\partial L_i}{\partial z_i^{(\ell)}} = \frac{\partial L_i}{\partial a_i^{(\ell)}} \cdot \frac{\partial a_i^{(\ell)}}{\partial z_i^{(\ell)}}.
$$

Where:

$$
\frac{\partial a_i^{(\ell)}}{\partial z_i^{(\ell)}} = \phi'\left(z_i^{(\ell)}\right), \qquad \frac{\partial L_i}{\partial a_i^{(\ell)}} = \left(W^{(\ell+1)}\right)^\top \delta_i^{(\ell+1)}.
$$

Substituting:

$$
\boxed{\delta_i^{(\ell)} = \left(\left(W^{(\ell+1)}\right)^\top \delta_i^{(\ell+1)}\right) \odot \phi'\left(z_i^{(\ell)}\right)}
$$

Finally, the gradients with respect to weights and biases at layer $\ell$:

$$
\frac{\partial L_i}{\partial W^{(\ell)}} = \delta_i^{(\ell)} \left(a_i^{(\ell-1)}\right)^\top, \qquad \frac{\partial L_i}{\partial b^{(\ell)}} = \delta_i^{(\ell)}.
$$

Thus, backpropagation allows us to propagate error information from the output layer to the hidden layers, and through the chain rule, helps precisely determine the direction and magnitude of the gradient for each parameter in the model.

### **5. Parameter Update**

After computing the gradient of the loss function with respect to each parameter during the backpropagation process, the next step is to adjust the parameters to reduce the model's error. The update mechanism is based on the **Gradient Descent** principle.

### Gradient Descent

Let $\theta$ be any parameter in the model

(for example: $W^{(1)}, b^{(1)}, \ldots, W^{(L+1)}, b^{(L+1)}$).

The parameter update rule at step $t$:

$$
\theta^{(t+1)} = \theta^{(t)} - \eta \frac{\partial L}{\partial \theta^{(t)}}.
$$

Where:

- $\eta > 0$: learning rate â€” controls the step size of the update
- $\frac{\partial L}{\partial \theta^{(t)}}$: gradient of the loss with respect to the parameter
- the "âˆ’" sign means we move in the **opposite** direction of the gradient (downward slope)

If $\eta$ is too large â†’ the model oscillates, does not converge.

If $\eta$ is too small â†’ learning is very slow.

---

### Stochastic Gradient Descent (SGD)

In practice, we do not always use the entire dataset to update once.

With SGD, the model is updated **after each sample** (or mini-batch):

Suppose $L_i$ is the loss of sample $i$ in epoch $t$.

$$
\theta^{(t+1)} = \theta^{(t)} - \eta \frac{\partial L_{i_k}}{\partial \theta^{(t)}}, \qquad i_k \in \{1, 2, \ldots, N\}.
$$

This formula means:

at each step, SGD selects one sample (or a small group of samples) and uses the gradient of that sample to update the parameters immediately.

This helps the model:

- converge faster,
- avoid getting stuck at saddle points,
- learn more effectively with large datasets.
---
### Summary

- Forward propagation â†’ generate predictions
- Backpropagation â†’ compute gradients
- Parameter update â†’ reduce error in the direction of gradient descent

All three steps are repeated continuously over many epochs until the model reaches optimal performance or the error reaches the desired level.

## **Example: Predicting Test Score from Study Hours**

### Problem Setup

Consider the following small dataset:

| Index | Self-study $x_1$ | Homework $x_2$ | Score $y$ |
|-------|------------------|----------------|-----------|
| 0     | 1                | 2              | 6         |
| 1     | 2                | 3              | 10        |
| 2     | 3                | 1              | 8         |
| 3     | 4                | 5              | 18        |

In this illustrative example, we will only consider **student B**:

$$
x = \begin{bmatrix} 2 \\ 3 \end{bmatrix}, \qquad y = 10.
$$

**Model: 1-layer MLP (linear regression)**

$$
\hat{y} = w^\top x + b, \qquad w \in \mathbb{R}^2, \, b \in \mathbb{R}.
$$

---

### Step 1. Parameter Initialization

**PyTorch Code**
```python
import torch

# Data for 1 student
x = torch.tensor([2.0, 3.0])    # [self-study, homework]
y = torch.tensor([10.0])        # score

# Initialize parameters
w = torch.zeros(2, requires_grad=True)  # w = [w1, w2]
b = torch.zeros(1, requires_grad=True)  # bias
```

**Solution**

Choose initial values:

$$
w^{(0)} = \begin{bmatrix} 0 \\ 0 \end{bmatrix}, \qquad b^{(0)} = 0.
$$

---

### Step 2. Forward Propagation

$$
\hat{y} = w^\top x + b.
$$

**PyTorch Code**
```python
y_hat = w @ x + b           # w^T x + b
print("y_hat =", y_hat.item())
```

**Solution**

$$
\hat{y} = \begin{bmatrix} 0 & 0 \end{bmatrix} \begin{bmatrix} 2 \\ 3 \end{bmatrix} + 0 = 0.
$$

Initial prediction: **0 points**.

### Step 3. Compute Loss (MSE)

We use MSE for 1 sample:

$$
L = (\hat{y} - y)^2.
$$

**PyTorch Code**
```python
loss = (y_hat - y) ** 2
print("loss =", loss.item())
```

**Solution**

$$
L = (0 - 10)^2 = 100.
$$

The error is quite large.

---

### Step 4. Backpropagation

**PyTorch Code**
```python
loss.backward()

print("dL/dw =", w.grad)  # gradient with respect to w (vector)
print("dL/db =", b.grad)  # gradient with respect to b (scalar)
```

**Solution (gradient in vector form)**

**1.** Derivative with respect to $\hat{y}$:

$$
\frac{\partial L}{\partial \hat{y}} = 2(\hat{y} - y) = 2(0 - 10) = -20.
$$

**2.** Since $\hat{y} = w^\top x + b$, we have:

$$
\frac{\partial \hat{y}}{\partial w} = x, \qquad \frac{\partial \hat{y}}{\partial b} = 1.
$$

**3.** Apply the chain rule:

$$
\frac{\partial L}{\partial w} = \frac{\partial L}{\partial \hat{y}} \cdot \frac{\partial \hat{y}}{\partial w} = -20 \, x = -20 \begin{bmatrix} 2 \\ 3 \end{bmatrix} = \begin{bmatrix} -40 \\ -60 \end{bmatrix},
$$

$$
\frac{\partial L}{\partial b} = \frac{\partial L}{\partial \hat{y}} \cdot 1 = -20.
$$

âŸ¹ PyTorch outputs approximately:

- `dL/dw = tensor([-40., -60.])`
- `dL/db = tensor([-20.])`

---

### Step 5. Parameter Update (Gradient Descent)

Choose learning rate $\eta = 0.01$.

**PyTorch Code**
```python
lr = 0.01

with torch.no_grad():           # disable autograd during update
    w -= lr * w.grad            # w_new = w_old - lr * dL/dw
    b -= lr * b.grad            # b_new = b_old - lr * dL/db

print("Updated w:", w)
print("Updated b:", b)

# Clear gradients for next iteration
w.grad.zero_()
b.grad.zero_()
```

**Solution**

$$
w_{\text{new}} = \begin{bmatrix} 0 \\ 0 \end{bmatrix} - 0.01 \begin{bmatrix} -40 \\ -60 \end{bmatrix} = \begin{bmatrix} 0.4 \\ 0.6 \end{bmatrix}, \qquad b_{\text{new}} = 0 - 0.01(-20) = 0.2.
$$

Prediction after update:

$$
\hat{y}_{\text{new}} = w_{\text{new}}^\top x + b_{\text{new}} = \begin{bmatrix} 0.4 & 0.6 \end{bmatrix} \begin{bmatrix} 2 \\ 3 \end{bmatrix} + 0.2 = 0.4 \cdot 2 + 0.6 \cdot 3 + 0.2 = 2.8.
$$

New loss:

$$
L_{\text{new}} = (2.8 - 10)^2 = 51.84 < 100.
$$

---

### Note: Using `nn.MSELoss` and `torch.optim.SGD`

In practice, we typically use PyTorch's built-in modules for cleaner code:
```python
import torch
import torch.nn as nn

x = torch.tensor([[2.0, 3.0]])  # add batch dimension
y = torch.tensor([[10.0]])

# Linear model: 2 inputs -> 1 output
model = nn.Linear(2, 1)

criterion = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.01)

# 2. Forward
y_hat = model(x)

# 3. Loss
loss = criterion(y_hat, y)

# 4. Backward
loss.backward()

# 5. Update
optimizer.step()
optimizer.zero_grad()
```

## **Conclusion**

The Multi-layer Perceptron is a crucial starting point in Deep Learning. By understanding how the model progresses from data to predictions, from errors to parameter adjustments, you have grasped the true essence of "machine learning."

The MLP is not just a basic model. It is the key that helps you understand more complex neural networks that follow. If you have carefully followed the steps from forward propagation to backpropagation, you now possess the most important perspective to step into the world of deep learning.

Understanding the MLP means you have built a solid foundation to look at Deep Learning at the deepest and clearest level.


### ðŸŽ“ Thank You for Reading!

I hope this guide helped you understand Multi-layer Perceptrons better. Keep learning, keep building, and never stop exploring! ðŸš€

*Happy Learning! ðŸ’¡*


